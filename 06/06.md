



[TOC]



#### **本期大纲**

![mark](http://web.iamyann.com/images/20200114/Gcj5g3gH8DNt.png?imageslim)







##### **在网格中部署应用**

先增加一个参数，把注入的结果输出为文件，并观察导出文件

```bash
cd /opt/k8s/work/istio_first/
istioctl kube-inject -f flask.istio.yaml -o flask.istio.injected.yaml
vi flask.istio.injected.yaml
```

vi flask.istio.injected.yaml

结果会发现，Deployment 部分和我们定义的配置文件有一些差别，多出了 Sidecar 容器和初始化容器的配置。



```sh
istio-init # 初始化容器，劫持应用通信的工具
```



直接使用导出文件也可以进行配置，不过要先把之前安装的配置删除，同时注意目录里不能有其他配置，防止误操作。

```
kubectl delete -f 
apply -f flask.istio.injected.yaml
```

没看到结果， 删除后重建ok



**对工作负载自行注入**

Istio 也支持对工作负载进行自动注入，需要 ConfigMap 来获知注入内容。需要执行用户可以访问集群中相应的 ConfigMap ，或使用本地配置文件。



```bash
kubectl -n istio-system get configmap istio-sidecar-injector
# istio-sidecar-injector   1      35h

kubectl -n istio-system get configmap istio-sidecar-injector -o=jsonpath='{.data.config}' > inject-config.yaml
  # 根据需要修改文件，然后注入
istioctl kube-inject --injectConfigFile inject-config.yaml
  # 测试失败，要么-f 试试
```

###### 获取 配置到 yaml

vi [kube-inject](./kube-inject)  获取更多信息



##### 对工作负载的要求

支持的工作负载的类型：

- Job
- DaemonSet
- ReplicaSet
- Pod
- Deployment



相应要求：

- 正确命名服务端口
- Pod 有关联的 Service



正确命名服务端口

Port 部分以协议名为前缀，http、http2、mongo、redis、grpc等，根据协议名提供服务，默认为 tcp 服务，功能很少。

这也就是之前配置写http的原因。



Pod 有关联的 Service

为了满足服务发现的需要， 所有 Pod 必须有关联服务，见之前示例 sleep。

另外建立增加两个标签 app 和 version ，同见示例。



##### 使用自动注入

自动注入和自行注入有啥差别。后面补充吧。



自动注入还是使用了 values.yaml

```yaml
vi install/kubernetes/helm/istio/values.yaml

autoInject: enabled  # 设置在启用自动注入后，是否对新建 Pod 进行操作
sidecarInjectorWebhook:
  enabled: true   # 开启自动注入
  replicaCount: 1
  image: sidecar_injector
  enableNamespacesByDefault: false  # 只注部分，否则全部命名空间
```

解析配置



其实是两块配置，具体看文档注释。目前配置只会自动注入 有 istio-injection: enabled 标签的命名空间。

对新建 Pos 那块 还有更详细的注解功能，同时作者列了一个表格来说明各种情况，全部等用到了再说吧，没有实操作容易混乱。



**测试自动注入**

会创建两个命名空间，并使用 sleep 来进行测试，让我们试试看。建立命名空间：



```bash
kubectl create ns auto
kubectl label namespaces auto istio-injection=enabled

kubectl get namespace --show-labels
kubectl create ns manually
```



分别部署应用：

```bash
kubectl apply -f sleep.yaml -n auto
kubectl get po -n auto

kubectl apply -f sleep.yaml -n manually
kubectl get po -n manually
```

部署时候的 -n 确实可以**指定 namespace** 

如果配置文件里自己有写呢？



**设置的优先级**：

注入行为是一个多级控制下的产物， 和 linux 的系统设置类似，细节的设置会替换更大范围的设置。相关设置罗列如下：



- 命名空间自带策略
- istio-system 空间 ConfigMap istio-sidecar-injector neverInjectSelector
- istio-system 空间 ConfigMap istio-sidecar-injector alwaysInjectSelector
- sidecar.istio.io/inject:"true/false"



查看 ConfigMap 配置

```sh
kubectl -n istio-system describe configmap \
 istio-sidecar-injector
```

相关的 configmap 有十多个



**日志查看**：

查看下 sidecar-injector pod 的日志

```bash
pod=$(kubectl -n istio-system get pods -l istio=sidecar-injector -o jsonpath='{.items[0].metadata.name}')

kubectl -n istio-system logs -f $pod
```

第一条命令是获取实时 pod 名称的，建议效仿。下面操作可以获得更详细的日志。

注意是data ，常见拼写错误



```sh
kubectl -n istio-system edit deployment \
 istio-sidecar-injector
# 添加参数,用完要去掉
        - --log_output_level=default:debug
```

位置：

![mark](http://web.iamyann.com/images/20200114/7BxNH1tBxa86.png?imageslim)



修改后，再次使用上一段的命令查看日志。



**注入失败排查**：

- 如查修改级别还是看不到日志，sidecar-injector 没有收到 pod 创建通知
- 检查命名空间标签，使用 --show-labels
- 检查 **MutatingWebhookConfiguration** 中的配置



```yaml
kubectl -n istio-system edit MutatingWebhookConfiguration \
 istio-sidecar-injector
 
  namespaceSelector:
    matchLabels:
      istio-injection: enabled
```



##### 准备测试应用

把 default 命名空间设为自动注入， 运行前一天的两个应用

```bash
kubectl label namespaces default istio-injection=enabled
kubectl apply -f sleep.istio.yaml
kubectl apply -f flask.istio.yaml
kubectl get po
```



##### **修改Istio配置**

变更 Istio 现有配置需求 ， 使用 Helm 的 --set 参数 完成。例如 关闭自动注入功能：

```bash
# helm template istio --name istio --namespace istio-system \
# --set sidecarInjectorWebhook.enabled=false

helm template install/kubernetes/helm/istio \
 --name istio --namespace istio-system \
 --set sidecarInjectorWebhook.enabled=true \
 -f myvalues.yaml > my-istio.yaml
kubectl apply -f my-istio.yaml

#deployment.extensions/istio-galley configured
#deployment.extensions/istio-pilot configured
```

sidecarInjectorWebhook 这个值不在 deployment 里面



经过测试发现，其并**没有提供删除功能**，只有 kubectl apply 操作。所以 -- set 只能处理新增或修改配置，对删除配置没有作用。



自动注入功能，由 k8s 的 mutating 控制器完成，其生成的配置对象，没法通过 --set 删除。



##### **使用Istio Dashboard**

Istio 的Dashboard 是定制了模板的 Grafana 。



##### 启用Grafana

默认服务没有开启， 启用的方式就是上节提到的 --set

```bash
# helm template istio --name istio --set grafana.enabled=true \
# --namespace istio-system > default-grafana.yaml

helm template install/kubernetes/helm/istio \
 --name istio --namespace istio-system \
 --set grafana.enabled=true \
> default-grafana.yaml

kubectl apply -f default-grafana.yaml
```



##### 访问Grafana

既然是 Grafana 访问端口还是 3000 ，通过端口转发的方式先查看一下。

```bash
kubectl -n istio-system port-forward \
$(kubectl -n istio-system get pod -l app=grafana -o jsonpath='{.items[0].metadata.name}') \
3000:3000 &
# Forwarding from 127.0.0.1:3000 -> 3000 在宿主机开放了本地 3000
```



通过宿主机的浏览器，查看本地的 3000 端口可以看到Grafana的页面， 点击 左上角的 Home，再点击 Istio 文件夹。

![mark](http://web.iamyann.com/images/20200114/iV3ncmVvWh46.png?imageslim)





制造一点流量，便于观察：

```bash
export SOURCE_POD=$(kubectl get pod -l app=sleep,version=v1 -o  jsonpath={.items..metadata.name})

kubectl exec -it -c sleep $SOURCE_POD bash

for i in `seq 100`; do http --body http://flaskapp/fetch?url=http://flaskapp/env/version >> /dev/null ;done
```



##### 开放Grafana服务

长期使用需要对 Grafana 服务进行定制，修改 values.yaml 中 关于 grafana 的定义。修改服务类型为 LoadBalance 或 创建 Ingress 对象，开启外网访问。同时开启 security.enabled 并设定账号密码。 



##### 学习和定制

Istio 提供了众多模板，数据来自 Prometheus，里面的语句和展示方法可以学习。通过编辑的方式，可以看到相关配置，同时 Grafana 配置支持导出。



##### **使用Prometheus**

Istio 集成 Prometheus 做为系统的监控组件。



##### 访问Prometheus

Prometheus 默认启用，直接端口转发就可以看到，同样是本机端口。

```bash
kubectl -n istio-system port-forward \
$(kubectl -n istio-system get pod -l app=prometheus -o jsonpath='{.items[0].metadata.name}') \
9090:9090 &
```

vi prometheus-istio-ingress.yaml



通过浏览器 打开 localhost:9090 可以看到查询界面。

```bash
istio_requests_total # 在浏览器中用以上命令查询
```



##### 开放Prometheus服务

与 Grafana 相同， 通过 values.yaml 定制服务开放。



##### 学习和定制

Istio 自带 Prometheus 的配置文件 ，保存在同名的 ConfigMap 中，可以定制或迁移，也可以配置 Alert Manager 进行告警。操作方法？



##### **使用Jaeger**

分布式跟踪组件，提供原生 OpenTracing 支持， 向下兼容 ZipKin，支持多种存储后端。默认只能跟踪调用环节，要支持整条链路还需要对应用改写。



##### 启用Jaeger

默认不启动，参考 Grafana 启动方式。



```bash
helm template install/kubernetes/helm/istio \
 --name istio --namespace istio-system \
 --set tracing.enabled=true \
> default-tracing.yaml

kubectl apply -f default-tracing.yaml
```



##### 访问Jaeger

同样开启端口转发：

```
kubectl -n istio-system port-forward \
$(kubectl -n istio-system get pod -l app=jaeger -o jsonpath='{.items[0].metadata.name}') \
16686:16686 &
```



再造一些数据：

```bash
kubectl exec -it sleep-v1-9c4699b9f-9wl9p -c sleep bash
for i in `seq 100`; do http --body http://flaskapp/env/version; done
```



刷新页面， 在Service 列表中选择 sleep 服务， 点击 Find Trace 按钮，就可以看到跟踪记录了。**一直失败**



##### 跟踪参数的传递

之前的测试只有简单的服务端 - 客户端，再启用一个服务端看下。

```bash
docker pull kennethreitz/httpbin
kubectl apply  -f samples/httpbin/httpbin.yaml
```



进入 sleep 容器调用 httpbin 服务的  /get 路径。

```bash
http --debug http://flaskapp/fetch_with_header?url=http://httpbin:8000/get
```



查看 httpie 客户端发出的原始信息和 flaskapp 接收到的请求，会发现多了一系列 X-*的请求 Header，就是 Envoy 附加的。



多次访问后， 反回 Jaeger 的web 界面，会发现 sleep 应用的跟踪记录非常少。没有完整的调用关系。需要中间服务把用于跟踪的Header 传递下去。具体归纳如下：



- x-request-id

- x-b3-traceid

- x-b3-spanid

- x-b3-parentspanid

- x-b3-sampled

- x-b3-flags

- x-ot-span-context



更新 flaskapp 的代码，提交 6.5.3 。

除了增加以上 Header，还添加了新的函数，保存上文涉及的Header，并在下次请求发送出去。再次测试



```bash
export SOURCE_POD=$(kubectl get pod -l app=sleep,version=v1 -o  jsonpath={.items..metadata.name})

kubectl exec -it -c sleep $SOURCE_POD bash

for i in `seq 100`; do http --body http://flaskapp/fetch?url=http://flaskapp/fetch_with_trace?url=http://httpbin:8080/ip ;done
```



再次打开 Jaeger 页面，查询 sleep 服务的跟踪结果，同时在进入容器进行命令测试。



```bash
http http://flaskapp/fetch_with_header?url=http://httpbin:8000/get 
```



![mark](http://web.iamyann.com/images/20200114/CnfRUMNnN3TK.png?imageslim)



##### 开放Jaeger服务

开放服务，除了上文的常规方法外， 利用 Chart也可以设置。

相关配置：

```yaml
vi values.yaml

    ingress:
      enabled: true
      hosts:
        - jaeger.local
      annotations:
      tls:
        # ...
```



##### **使用Kiali**

Istio 的专属可视化软件，提供监控、可视化、跟踪，还有 Istio的配置验证、健康评估。



##### 启用Kiali

打开方式和前面的软件相同，可以考虑使用最新版本。

```sh
helm template install/kubernetes/helm/istio \
 --name istio --namespace istio-system \
 --set kiali.enabled=true \
> default-kiali.yaml

kubectl apply -f default-kiali.yaml
```



##### 访问Kiali

端口转发：

```bash
kubectl -n istio-system port-forward \
$(kubectl -n istio-system get pod -l app=kiali -o jsonpath='{.items[0].metadata.name}') \
20001:20001 &
```



本地浏览器访问， 其他服务器请使用 nginx 转发。默认帐号为 admin：admin ，

在 default 命名空间可以看到各服务情况。



在 Graph 菜单 还可以服务的拓扑关系， 另外还有 Istio Config 项， 选择 istio-system 命名空间，可以看到 Isto 默认自定义资源的设置情况。



##### 开放Kiali服务

开放访问同 Jaeger， 同样可以通过 values.yaml 开启。



其他成功，jaeger 无显示， kiali 有个报错

